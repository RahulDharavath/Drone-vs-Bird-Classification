# -*- coding: utf-8 -*-
"""BirdVSDrone_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dfjAtN0DdRhEksFoPj8mON0Us3yytrE4

# **Binary Image Classification (Drone-Vs-Bird)**

#STEP 1: Setup Kaggle in Colab
"""

!mkdir -p ~/.kaggle
!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""# STEP 2: Download Dataset & Unzip:"""

# !kaggle datasets download -d harshwalia/birds-vs-drone-dataset -p ./ --unzip
!kaggle datasets download -d muhammadsaoodsarwar/drone-vs-bird -p ./ --unzip

"""#STEP 1: Import Libraries"""

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout

# Conv2D --> Applies convolution filters to extract image features (edges, shapes).
# MaxPool2D --> Reduces image size while keeping important information.
# Flatten --> Converts 2D feature maps â†’ 1D vector for Dense layers.
# Dense --> Fully connected layers.

"""---
  * Batch size : the model processes images in batches, not all at once.

  * updates weights after each batch.

  `How training happens in ONE EPOCH:`

  Batch	   --->    Images processed

Batch 1	   --->     Image 1 â†’ Image 32

Batch 2	   --->     Image 33 â†’ Image 64

Batch 3	   --->     Image 65 â†’ Image 96

Batch 4	   --->     Image 97 â†’ Image 100   (only 4 images)

So:

* 4 batches = 1 epoch.
* Model updates weights after every batch.

---
Why NOT send all images at once?

âŒ If batch size = 100
* High memory usage
* Slower convergence
* Less noisy gradients (can get stuck)

âŒ If batch size = 1
* Very slow
* Very noisy updates

âœ… Batch size = 32
* Fits GPU memory
* Faster training
* Stable gradients

This is why 32 is the industry default.

---
IMPORTANT:

One batch = one weight update.

One epoch = model sees all images once
"""

import os
from collections import Counter

def count_images(root):
    counter = Counter()
    total = 0
    for subdir, _, files in os.walk(root):
        for f in files:
            ext = os.path.splitext(f)[1].lower()
            if ext in ['.jpg', '.jpeg', '.png', '.webp', '.gif', '.bmp']:
                counter[ext] += 1
                total += 1
    print("Total images:", total)
    print(counter)

count_images("dataset")

"""Total images: 4106
Counter({'.jpg': 3278, '.jpeg': 778, '.png': 48, '.webp': 2})

Total bird images: 1605
Counter({'.jpg': 1207, '.jpeg': 396, '.png': 2})

Total drone images: 2499
Counter({'.jpg': 2071, '.jpeg': 382, '.png': 46})

"""

import os

def remove_webp(root_folder):
    removed = 0

    for subdir, _, files in os.walk(root_folder):
        for file in files:
            if file.lower().endswith(".webp"):
                file_path = os.path.join(subdir, file)
                os.remove(file_path)
                removed += 1
                print(f"ðŸ—‘ Removed: {file_path}")

    print(f"\nâœ… Total .webp files removed: {removed}")


remove_webp("dataset")

from pathlib import Path
import imghdr
import os

dataset_path = "/content/dataset"
bad_files = []

for filepath in Path(dataset_path).rglob("*"):
    if filepath.is_file():
        # Check extension
        if filepath.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            # Check ACTUAL content
            img_type = imghdr.what(filepath)
            if img_type is None or img_type not in ['jpeg', 'png', 'gif', 'bmp']:
                bad_files.append(str(filepath))
                # print(f"âŒ BAD FILE: {filepath} (claims {filepath.suffix}, actual: {img_type})")

print(f"\nðŸš¨ Found {len(bad_files)} corrupted files!")
if bad_files:
    print("First 5 bad files:")
    for f in bad_files[:5]:
        print(f"  - {f}")

from PIL import Image
import os
from pathlib import Path

dataset_path = "/content/dataset"

def mass_pil_convert():
    """Convert ALL files using PIL (bulletproof)"""
    total_fixed = 0

    for folder in ['drone', 'bird']:
        folder_path = os.path.join(dataset_path, folder)

        for filepath in Path(folder_path).iterdir():
            if filepath.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                try:
                    # PIL fixes everything
                    img = Image.open(filepath).convert('RGB')
                    img.save(filepath, 'JPEG', quality=95)  # Overwrite as proper JPEG
                    total_fixed += 1
                except Exception as e:
                    print(f"âŒ True corrupt {filepath}: {e}")
                    os.remove(filepath)  # Delete truly broken

    print(f"âœ… Fixed {total_fixed} files with PIL!")

mass_pil_convert()

"""---
# STEP 2: Load Dataset
---
"""

train_ds = keras.utils.image_dataset_from_directory(
    directory = "/content/dataset",
    validation_split = 0.2,         # 20% for validation
    subset = "training",            # Take 80% for training
    labels = "inferred",            # Auto-generates labels from folder names ('bird'=0, 'drone'=1 )
    label_mode = "int",             # Returns integer labels (0,1)
    batch_size = 32,
    image_size = (224,224),
    seed = 123
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory = "/content/dataset",
    validation_split = 0.2,
    subset = "validation",         # Take 20% for validation
    labels = "inferred",
    label_mode = "int",
    batch_size = 32,              # the model it processes images in batches.
    image_size = (224,224),
    seed = 123
)

print("Classes:", train_ds.class_names)

"""# STEP 3: Normalize 0 to 1 range.
  * Before normalizing pixel values 0 - 255.
  * After normalized pixel values 0 - 1.
"""

def process(image, label):
  image = tf.cast(image, tf.float32) / 255.0
  return image, label

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process)

"""# OPTIMIZE PERFORMANCE
* for Faster training.
* When to Use:
  * Dataset is large. (10k-50k)
  * Transfer learning.
  * Video frames.
"""

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.prefetch(buffer_size= AUTOTUNE)
validation_ds = validation_ds.prefetch(buffer_size= AUTOTUNE)

"""# STEP 4: CNN Model"""

model = Sequential()

# First conv layer.
# Applies 32 filters of size 3x3. Learns: i.Edges, ii.Corners
model.add(Conv2D(32, kernel_size=(3,3), padding="valid", activation = "relu", input_shape=(224,224,3)))

# MaxPooling reduces size by half.
    # Learns --> Textures, Small shapes, Object parts
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding="valid"))

# Second conv layer.
model.add(Conv2D(64, kernel_size=(3,3), padding="valid", activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding="valid"))

# Third conv layer.
    # Learns --> Complex patterns. like --> Drone structure vs bird wings
model.add(Conv2D(128, kernel_size=(3,3), padding="valid", activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding="valid"))

# Converts 3D feature maps â†’ 1D vector
model.add(Flatten())

# Dense(128): learns high-level combinations
# Dense(64): refines decision
# Dense(1): outputs probability
model.add(Dense(128, activation="relu"))
model.add(Dense(64, activation="relu"))
model.add(Dense(1, activation="sigmoid"))

model.summary()

model.compile(loss = "binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history = model.fit(train_ds, epochs=10, validation_data=validation_ds)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], color='red', label='train')
plt.plot(history.history['val_accuracy'], color='blue', label='validation')
plt.title('Model Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], color='red', label='train')
plt.plot(history.history['val_loss'], color='yellow', label='validation')
plt.title('Model Loss')
plt.legend()
plt.show()

model.save("basic_cnn_drone_vs_bird_model.keras")

"""# test model"""

import cv2
import numpy as np

bird = cv2.imread('/content/dataset/bird/100.jpg')
drone = cv2.imread('/content/dataset/drone/000000000000.jpg')

print("Bird Image Size:", bird.shape)
print("Drone Image Size:", drone.shape)

plt.imshow(bird)

plt.imshow(drone)

bird = cv2.resize(bird, (224,224))
drone = cv2.resize(drone, (224,224))

print("Bird Image Size:", bird.shape)
print("Drone Image Size:", drone.shape)

bird_input = bird.reshape((1,224,224,3))
drone_input = drone.reshape((1,224,224,3))

print('Bird -->',model.predict(bird_input))
print('Drone -->', model.predict(drone_input))

pred = model.predict(img)
print(float(pred[0][0]))
print(f"{pred[0][0]:.8f}")

model.predict(drone_input)

IMG_SIZE = (224,224)

def prepare_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, IMG_SIZE)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    return img

img = prepare_image("/content/dataset/bird/100.jpg")
# img = prepare_image("/content/dataset/drone/000000000000.jpg")
pred = model.predict(img)[0][0]

label = "Drone" if pred > 0.5 else "Bird"
confidence = pred if pred > 0.5 else 1 - pred

print(f"Prediction: {label} | Confidence: {confidence:.2f}")

"""## The above plot it is clear indication for Overfitting.

## Here are the ways to reduce Overfitting.

##1. Add more data
##2. Data Augmentation
##3. L1/L2 Regularizer
##4. Dropout
##5. Batch Norm
##6. Reduce complexity

# using Dropout & Batch Norm to reduce overfitting.
"""

model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))                  # 10% neurons are randomly turned OFF during training.
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history2 = model.fit(train_ds, epochs=5, validation_data= validation_ds)

plt.plot(history2.history['accuracy'], color='red', label='train')
plt.plot(history2.history['val_accuracy'], color='yellow', label='validation')
plt.title('Model Accuracy')
plt.legend()
plt.show()

plt.plot(history2.history['loss'], color='red', label='train')
plt.plot(history2.history['val_loss'], color='yellow', label='validation')
plt.title('Model Loss')
plt.legend()
plt.show()

"""# test model"""

import cv2
import numpy as np

IMG_SIZE = (224,224)

def prepare_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, IMG_SIZE)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    return img

# img = prepare_image("1.JPEG")
# img = prepare_image("/content/dataset/bird/100.jpg")
# img = prepare_image("/content/dataset/drone/000000000000.jpg")
pred = model.predict(img)[0][0]

label = "Drone" if pred > 0.5 else "Bird"
confidence = pred if pred > 0.5 else 1 - pred

print(f"Prediction: {label} | Confidence: {confidence:.2f}")

bird = cv2.imread('/content/singleBirdinsky58.jpeg')
drone = cv2.imread('/content/1.JPEG')

print("Bird Image Size:", bird.shape)
print("Drone Image Size:", drone.shape)

bird = cv2.resize(bird, (224,224))
drone = cv2.resize(drone, (224,224))

print("Bird Image Size:", bird.shape)
print("Drone Image Size:", drone.shape)

# Reshape images
bird_input = bird.reshape((1,224,224,3))
drone_input = drone.reshape((1,224,224,3))

print('Bird --> ', model.predict(bird_input))
print('-'*20)
print('Drone --> ', model.predict(drone_input))

# model.save("bird_drone_cnn_model")

# 1ï¸âƒ£ Improve accuracy (BatchNorm + Dropout)
# 2ï¸âƒ£ Data augmentation
# 3ï¸âƒ£ Confusion matrix + predictions
# 4ï¸âƒ£ Transfer learning (MobileNet)
# 5ï¸âƒ£ Drone vs Bird video detection pipeline

"""#**Data Augmentation**

#STEP 1: Imports
"""

import tensorflow
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Dropout
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import cv2
import matplotlib.pyplot as plt

"""# STEP 2: Create ImageDataGenerator"""

train_datagen = ImageDataGenerator(
    rescale=1./255,          # Normalize pixels
    rotation_range=20,       # Rotate images
    zoom_range=0.2,          # Zoom in/out
    width_shift_range=0.1,   # Horizontal shift
    height_shift_range=0.1,  # Vertical shift
    horizontal_flip=True,    # Flip images
    validation_split=0.2     # 80% train / 20% validation
)

val_datagen = ImageDataGenerator(
    rescale = 1./255,
    validation_split = 0.2
)

"""# STEP 3: Load the training and validation datasets"""

train_ds = train_datagen.flow_from_directory(
    directory = "/content/dataset",
    target_size = (224,224),
    batch_size = 32,
    class_mode = 'binary',
    subset = 'training',
    seed = 123
)

val_ds = val_datagen.flow_from_directory(
    directory = "/content/dataset",
    target_size = (224,224),
    batch_size = 32,
    class_mode = 'binary',
    subset = 'validation',
    seed = 123
)

print(train_ds.class_indices)

"""#STEP 4: Build CNN Model"""

model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(2,2))

model.add(Conv2D(128, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(2,2))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))

model.add(Dense(1, activation='sigmoid'))

model.summary()

"""#STEP 5: Compile Model"""

model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#STEP 6: Train Model"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history = model.fit(train_ds, epochs=5, validation_data=val_ds)

"""#STEP 7: Plot Accuracy & Loss"""

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title("Model Accuracy")
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title("Model Loss")
plt.show()

"""#STEP 9: Predict on Single Image"""

import cv2
import numpy as np

IMG_SIZE = (224,224)

def prepare_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, IMG_SIZE)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    return img

img = prepare_image("/content/1.JPEG")
pred = model.predict(img)[0][0]

label = "Drone" if pred > 0.5 else "Bird"
confidence = pred if pred > 0.5 else 1 - pred

print(f"Prediction: {label} | Confidence: {confidence:.2f}")



"""---
# NEW DATA AUGMENTATION (MODERN WAY)
* Uses: tf.keras.layers
* Works inside the model
* Saved automatically with model
---

#STEP 1: Imports
"""

import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.models import Sequential
import matplotlib.pyplot as plt

"""#STEP 2: Load Dataset"""

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
SEED = 123

train_ds = keras.utils.image_dataset_from_directory(
    "/content/drive/MyDrive/BirdVsDrone",
    validation_split=0.2,
    subset="training",
    seed=SEED,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE
)

val_ds = keras.utils.image_dataset_from_directory(
    "/content/drive/MyDrive/BirdVsDrone",
    validation_split=0.2,
    subset="validation",
    seed=SEED,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE
)

class_names = train_ds.class_names
print("Classes:", class_names)

"""# STEP 3: Normalize Images"""

def normalize(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

train_ds = train_ds.map(normalize)
val_ds = val_ds.map(normalize)

"""#STEP 4: NEW DATA AUGMENTATION

"""

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.1),
])

"""#STEP 5: Performance Optimization

"""

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(AUTOTUNE)
val_ds = val_ds.prefetch(AUTOTUNE)

"""#STEP 6: CNN MODEL

"""

model = Sequential([

    data_augmentation,  # ðŸ”¥ FIRST layer

    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
    layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(2,2),

    layers.Flatten(),

    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),

    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),

    layers.Dense(1, activation='sigmoid')
])

"""#STEP 7: Compile Model

"""

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

"""#STEP 8: Train Model"""

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=5
)

"""#STEP 9: Plot Results"""

plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title("Accuracy")
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title("Loss")
plt.legend()
plt.show()



"""# test model"""

import cv2
import numpy as np

bird = cv2.imread('/content/singleBirdinsky58.jpeg')
drone = cv2.imread('/content/1.JPEG')

print("Bird Image Size:", bird.shape)
print("Drone Image Size:", drone.shape)

bird = cv2.resize(bird, (224,224))
drone = cv2.resize(drone, (224,224))

print("Bird Image Size:", bird.shape)
print("Drone Image Size:", drone.shape)

# Reshape images
bird_input = bird.reshape((1,224,224,3))
drone_input = drone.reshape((1,224,224,3))

print('Bird --> ', model.predict(bird_input))
print('-'*20)
print('Drone --> ', model.predict(drone_input))

"""---
# Transfer Learning
---

# Setup Kaggle in Colab
"""

!mkdir -p ~/.kaggle
!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""#  Download Dataset & Unzip:"""

!kaggle datasets download -d muhammadsaoodsarwar/drone-vs-bird -p ./ --unzip

"""---
#STEP 1: Import Libraries
---
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from collections import Counter

from keras.applications.mobilenet_v2 import preprocess_input

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, BatchNormalization, Dropout
from keras import layers
from keras.applications import MobileNetV2
from keras.metrics import F1Score
from keras.callbacks import EarlyStopping, ReduceLROnPlateau


# Conv2D --> Applies convolution filters to extract image features (edges, shapes).
# MaxPool2D --> Reduces image size while keeping important information.
# Flatten --> Converts 2D feature maps â†’ 1D vector for Dense layers.
# Dense --> Fully connected layers.

"""---
# Check the Image Formats
---
"""

def count_images(pathdir):
    counter = Counter()   # 1
    total = 0

    for subdir, _, files in os.walk(pathdir):  # 2
        for f in files:
            ext = os.path.splitext(f)[1].lower()   # 3
            if ext in ['.jpg', '.jpeg', '.png', '.webp', '.gif', '.bmp']:
                counter[ext] += 1
                total += 1

    print("Total images:", total)
    print(counter)

count_images("/content/dataset")


# comments
# 1. --> "Counter" â†’ It counts how many .jpg files, .jpeg, .png files are there
# 2. --> "subdir" â†’ the current folder itâ€™s looking at.
#    --> "_" â†’ a placeholder for subfolders.
#    --> "files" â†’ a list of all files in the current folder.
# 3. -->  os.path.splitext(f) â†’ splits the file name into:
#         i)-> "name" â†’ cat.jpg â†’ cat.
#         ii)-> "extension" â†’ cat.jpg â†’ .jpg.
#         iii) [1] â†’ we only take the extension.
#         iv) "lower()" â†’ converts .JPG into .jpg

"""---
# Remove webp
---
"""

def remove_webp(root_folder):
    """Remove all WebP files from dataset recursively"""
    removed = 0

    for subdir, _, files in os.walk(root_folder):
        for f in files:
            if f.lower().endswith('.webp'):
                webp_path = os.path.join(subdir, f)
                os.remove(webp_path)
                removed += 1
                print(f" Removed: {webp_path}")

    print(f"\n Total WebP files Removed: {removed}")



# Run the function
remove_webp("/content/dataset")

"""---
# Fix Corrupt Images
---
"""

import os
from PIL import Image

dataset_path = "/content/dataset"

fixed = 0
deleted = 0

for root, _, files in os.walk(dataset_path):
  for f in files:
    file_path = os.path.join(root, f)

    if f.lower().endswith(('.jpg', '.jpeg', '.png')):
      try:
        img = Image.open(file_path)
        img.save(file_path, "JPEG", quality=95, subsampling=0)
        fixed += 1

      except Exception:
        os.remove(file_path)
        deleted += 1

print("Fixed images:", fixed)
print("Deleted unreadable images:", deleted)

"""---
# STEP 2: Load Dataset
---
"""

train_ds = keras.utils.image_dataset_from_directory(
    directory = "/content/dataset",
    validation_split = 0.2,         # 20% for validation
    subset = "training",            # Take 80% for training
    label_mode = "int",             # Returns integer labels (0,1)
    batch_size = 32,
    image_size = (224,224),
    seed = 123
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory = "/content/dataset",
    validation_split = 0.2,
    subset = "validation",         # Take 20% for validation
    label_mode = "int",
    batch_size = 32,              # the model it processes images in batches.
    image_size = (224,224),
    seed = 123
)

print("Classes:", train_ds.class_names)

"""---
# STEP 3: Preprocessing (MobileNetV2)
---
"""

def preprocess(image, label):
    image = preprocess_input(image)
    return image, label

# Apply normalization to datasets:
train_ds = train_ds.map(preprocess, num_parallel_calls= tf.data.AUTOTUNE)
validation_ds = validation_ds.map(preprocess, num_parallel_calls= tf.data.AUTOTUNE)

"""---
#STEP 4: OPTIMIZE PERFORMANCE (prefetch)
---
* for Faster training.
* When to Use:
  * Dataset is large. (10k-50k)
  * Transfer learning.
  * Video frames.
"""

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.prefetch(buffer_size= AUTOTUNE)
validation_ds = validation_ds.prefetch(buffer_size= AUTOTUNE)

"""---
#STEP 5: Add Augmentation Using `Keras Preprocessing Layers` --> runs on GPU.
---

## `ImageDataGenerator` --> which runs on the CPU.
---
## Why is it Imp?
* Makes model robust.
* Prevents overfitting.

"""

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.2)
])

def augment(image, label):
    image = data_augmentation(image, training=True)
    return image, label

train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)

"""---
# STEP 6: Load Pretrained Model -> MobileNetV2 (Transfer Learning)
---
"""

conv_base = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_shape=(224,224,3)
)

# here we freezing conv(not changing anything in MobileNetV2 conv part)
conv_base.trainable = False

conv_base.summary()

"""---
# STEP 7: Build Model
---
## Global Average Pooling:
* Fewer parameters
* Less overfitting
* Better generalization
"""

inputs = keras.Input(shape=(224, 224, 3))

x = conv_base(inputs, training= False)
x = layers.GlobalAveragePooling2D()(x)

x = layers.Dense(256, activation="relu")(x)
x = layers.Dropout(0.3)(x)

outputs = layers.Dense(1, activation="sigmoid")(x)

model = keras.Model(inputs, outputs)
model.summary()

"""---
# STEP 8: Compile Model
---
"""

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-4),
    loss="binary_crossentropy",
    metrics=["accuracy",
             keras.metrics.Precision(name="precision"),
             keras.metrics.Recall(name="recall"),
             keras.metrics.AUC(name="auc")
             ]
)

"""# STEP 9: Add EarlyStopping"""

callback = EarlyStopping(
    monitor = 'val_loss',
    patience = 5,                # Stop after 5 epochs no improvement
    restore_best_weights=True,   # Revert to best model
    verbose=1
)

# It automatically reduces the learning rate when your model stops improving.
# Dynamically adjusts the learning rate if the model gets "stuck".
lr_scheduler = ReduceLROnPlateau(
    monitor = 'val_loss',
    factor = 0.2,
    patience = 3,
    min_lr = 1e-6,
    verbose=1
)

"""# STEP 10: Train Model"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history = model.fit(train_ds,
#                     epochs = 35,
#                     validation_data = validation_ds,
#                     callbacks= [callback, lr_scheduler])
#

"""
Epoch 1/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 266s 2s/step - accuracy: 0.7596 - auc: 0.8448 - loss: 0.4795 - precision: 0.8364 - recall: 0.7503 - val_accuracy: 0.9146 - val_auc: 0.9885 - val_loss: 0.2231 - val_precision: 0.8841 - val_recall: 0.9900 - learning_rate: 1.0000e-04
Epoch 2/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 289s 3s/step - accuracy: 0.9224 - auc: 0.9750 - loss: 0.1975 - precision: 0.9385 - recall: 0.9350 - val_accuracy: 0.9463 - val_auc: 0.9924 - val_loss: 0.1496 - val_precision: 0.9271 - val_recall: 0.9900 - learning_rate: 1.0000e-04
Epoch 3/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 289s 3s/step - accuracy: 0.9414 - auc: 0.9878 - loss: 0.1428 - precision: 0.9569 - recall: 0.9478 - val_accuracy: 0.9585 - val_auc: 0.9932 - val_loss: 0.1195 - val_precision: 0.9465 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 4/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 290s 3s/step - accuracy: 0.9590 - auc: 0.9888 - loss: 0.1208 - precision: 0.9642 - recall: 0.9685 - val_accuracy: 0.9585 - val_auc: 0.9952 - val_loss: 0.1123 - val_precision: 0.9465 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 5/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 250s 2s/step - accuracy: 0.9622 - auc: 0.9927 - loss: 0.1060 - precision: 0.9710 - recall: 0.9666 - val_accuracy: 0.9598 - val_auc: 0.9954 - val_loss: 0.1140 - val_precision: 0.9483 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 6/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 250s 2s/step - accuracy: 0.9721 - auc: 0.9958 - loss: 0.0833 - precision: 0.9750 - recall: 0.9791 - val_accuracy: 0.9634 - val_auc: 0.9963 - val_loss: 0.1004 - val_precision: 0.9538 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 7/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 255s 2s/step - accuracy: 0.9731 - auc: 0.9951 - loss: 0.0836 - precision: 0.9745 - recall: 0.9819 - val_accuracy: 0.9634 - val_auc: 0.9964 - val_loss: 0.0902 - val_precision: 0.9555 - val_recall: 0.9860 - learning_rate: 1.0000e-04
Epoch 8/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 267s 3s/step - accuracy: 0.9846 - auc: 0.9972 - loss: 0.0639 - precision: 0.9883 - recall: 0.9863 - val_accuracy: 0.9610 - val_auc: 0.9963 - val_loss: 0.0979 - val_precision: 0.9518 - val_recall: 0.9860 - learning_rate: 1.0000e-04
Epoch 9/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 292s 3s/step - accuracy: 0.9706 - auc: 0.9962 - loss: 0.0786 - precision: 0.9728 - recall: 0.9795 - val_accuracy: 0.9646 - val_auc: 0.9963 - val_loss: 0.0934 - val_precision: 0.9574 - val_recall: 0.9860 - learning_rate: 1.0000e-04
Epoch 10/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 294s 3s/step - accuracy: 0.9727 - auc: 0.9966 - loss: 0.0705 - precision: 0.9799 - recall: 0.9746 - val_accuracy: 0.9671 - val_auc: 0.9967 - val_loss: 0.0874 - val_precision: 0.9593 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 11/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 296s 3s/step - accuracy: 0.9810 - auc: 0.9982 - loss: 0.0570 - precision: 0.9809 - recall: 0.9881 - val_accuracy: 0.9744 - val_auc: 0.9968 - val_loss: 0.0781 - val_precision: 0.9706 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 12/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 253s 2s/step - accuracy: 0.9869 - auc: 0.9979 - loss: 0.0558 - precision: 0.9889 - recall: 0.9895 - val_accuracy: 0.9671 - val_auc: 0.9967 - val_loss: 0.0862 - val_precision: 0.9593 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 13/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 256s 2s/step - accuracy: 0.9835 - auc: 0.9989 - loss: 0.0471 - precision: 0.9868 - recall: 0.9861 - val_accuracy: 0.9646 - val_auc: 0.9965 - val_loss: 0.0876 - val_precision: 0.9574 - val_recall: 0.9860 - learning_rate: 1.0000e-04
Epoch 14/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 2s/step - accuracy: 0.9845 - auc: 0.9990 - loss: 0.0434 - precision: 0.9875 - recall: 0.9872
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 292s 3s/step - accuracy: 0.9845 - auc: 0.9990 - loss: 0.0434 - precision: 0.9875 - recall: 0.9872 - val_accuracy: 0.9683 - val_auc: 0.9968 - val_loss: 0.0857 - val_precision: 0.9612 - val_recall: 0.9880 - learning_rate: 1.0000e-04
Epoch 15/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 256s 2s/step - accuracy: 0.9821 - auc: 0.9981 - loss: 0.0556 - precision: 0.9842 - recall: 0.9865 - val_accuracy: 0.9683 - val_auc: 0.9969 - val_loss: 0.0824 - val_precision: 0.9612 - val_recall: 0.9880 - learning_rate: 2.0000e-05
Epoch 16/35
103/103 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 267s 3s/step - accuracy: 0.9861 - auc: 0.9991 - loss: 0.0406 - precision: 0.9857 - recall: 0.9917 - val_accuracy: 0.9695 - val_auc: 0.9968 - val_loss: 0.0794 - val_precision: 0.9630 - val_recall: 0.9880 - learning_rate: 2.0000e-05
Epoch 16: early stopping
Restoring model weights from the end of the best epoch: 11.
CPU times: user 1h 34min 1s, sys: 16min 58s, total: 1h 51min
Wall time: 1h 12min 41s

26/26 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 53s 2s/step - accuracy: 0.9702 - auc: 0.9959 - loss: 0.0908 - precision: 0.9667 - recall: 0.9840
Validation Loss: 0.0781
Validation Accuracy: 0.9744
Validation Precision: 0.9706
Validation Recall: 0.9880
Validation AUC: 0.9968

"""

loss, acc, prec, rec, auc_score = model.evaluate(validation_ds)
print(f"Validation Loss: {loss:.4f}")
print(f"Validation Accuracy: {acc:.4f}")
print(f"Validation Precision: {prec:.4f}")
print(f"Validation Recall: {rec:.4f}")
print(f"Validation AUC: {auc_score:.4f}")

"""# STEP 11: Plot Results"""

import matplotlib.pyplot as plt

def plot_metrics(history):
    metrics = [
        ("accuracy", "Accuracy"),
        ("precision", "Precision"),
        ("recall", "Recall"),
        ("auc", "AUC"),
        ("loss", "Loss")
    ]

    plt.figure(figsize=(15, 12))

    for i, (metric, title) in enumerate(metrics, 1):
        plt.subplot(3, 2, i)

        plt.plot(history.history[metric], label=f"Train {title}")
        plt.plot(history.history[f"val_{metric}"], label=f"Val {title}")

        plt.xlabel("Epochs")
        plt.ylabel(title)
        plt.title(f"Training vs Validation {title}")
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.show()

# Run it.
plot_metrics(history)

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy")
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.show()

plt.plot(history.history['precision'], label='train Precision')
plt.plot(history.history['val_precision'], label='Validation Precision')
plt.title("Precision")
plt.legend()
plt.show()

plt.plot(history.history['recall'], label= 'Train Recall')
plt.plot(history.history['val_recall'], label= 'Validation Recall')
plt.xlabel("Epochs")
plt.ylabel("Recall")
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

IMG_SIZE = (224,224)

def prepare_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, IMG_SIZE)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    return img

img = prepare_image("/content/dataset/bird/singleBirdinsky108_brighter.jpg")
# img = prepare_image("/content/dataset/drone/100302.jpg")
# img = prepare_image("/content/dataset/drone/000000000875.jpg")
# img = prepare_image("/content/images.jpeg")
# img = prepare_image("/content/Drone-Light-Show-2-1024x683.jpeg")
pred = model.predict(img)


print(float(pred[0][0]))



label = "Drone" if pred > 0.9 else "Bird"
confidence = pred if pred > 0.9 else 1 - pred

print(f"Prediction: {label} | Confidence: {confidence[0][0]:.3f}")

model.save("Drone_Vs_Bird_Model.keras")

"""# Test the Model"""

DATASET = "/content/drive/MyDrive/BirdVsDrone"
IMG_SIZE = (224,224)
BATCH_SIZE = 32

# --- Apply image fixing to the new dataset ---
import os
from PIL import Image

fixed_count = 0
deleted_count = 0

for root, _, files in os.walk(DATASET):
  for f in files:
    file_path = os.path.join(root, f)

    if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):
      try:
        img = Image.open(file_path)
        img.save(file_path, "JPEG", quality=95, subsampling=0)
        fixed_count += 1

      except Exception:
        os.remove(file_path)
        deleted_count += 1
    elif not f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):
        # Delete non-image files if any remain
        os.remove(file_path)
        deleted_count += 1
        print(f"Deleted non-image file: {file_path}")

print(f"Fixed images in {DATASET}: {fixed_count}")
print(f"Deleted unreadable/non-image files in {DATASET}: {deleted_count}")
# ----------------------------------------------


test_ds = keras.utils.image_dataset_from_directory(
    directory = DATASET,
    image_size = IMG_SIZE,
    batch_size = BATCH_SIZE,
    shuffle = False
)

test_ds = test_ds.map(lambda x,y: (preprocess_input(x), y))

results = model.evaluate(test_ds)

# Explicitly define metric names in the expected order
metric_names = ['loss', 'accuracy', 'precision', 'recall', 'auc']

for name, value in zip(metric_names, results):
  print(f"{name}: {value:.4f}")

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

y_true, y_pred = [], []

for images, labels in test_ds:
    preds = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(preds.flatten())

y_pred = (np.array(y_pred) >= 0.9).astype(int)

print(classification_report(y_true, y_pred, target_names=["Bird", "Drone"]))

cm = confusion_matrix(y_true, y_pred)
print(cm)

import matplotlib.pyplot as plt

def plot_metric(history, metric):
    plt.plot(history.history[metric])
    plt.plot(history.history[f"val_{metric}"])
    plt.title(metric.upper())
    plt.xlabel("Epoch")
    plt.ylabel(metric)
    plt.legend(["Train", "Val"])
    plt.show()

plot_metric(history, "accuracy")
plot_metric(history, "loss")
plot_metric(history, "auc")
plot_metric(history, "precision")
plot_metric(history, "recall")

from sklearn.metrics import precision_recall_curve

precision, recall, thresholds = precision_recall_curve(y_true, y_pred)

plt.plot(thresholds, precision[:-1], label="Precision")
plt.plot(thresholds, recall[:-1], label="Recall")
plt.xlabel("Threshold")
plt.legend()
plt.show()

IMG_SIZE = (224,224)

def prepare_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, IMG_SIZE)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    return img

img = prepare_image("/content/Drone-Light-Show-2-1024x683.jpeg") # Re-prepare the image
pred = model.predict(img)[0][0]
label = "Drone" if pred >= 0.9 else "Bird"

# keras.models.load_model("/content/drive/MyDrive/drone_vs_bird_model.keras")
model = keras.models.load_model("/content/Drone_Vs_Bird_Model.keras")

model.summary()

# Assuming you have a test_ds prepared similarly to your train_ds
results = model.evaluate(validation_ds)
print(f"Test Loss: {results[0]}, Test Accuracy: {results[1]}")

IMG_SIZE = (224,224)

def prepare_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, IMG_SIZE)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    return img

img = prepare_image("/content/drive/MyDrive/BirdVsDrone/Birds/singleBirdinsky79.jpeg")
# img = prepare_image("/content/drive/MyDrive/BirdVsDrone/Drones/singleDronesinsky366.jpeg")
pred = model.predict(img)


print(float(pred[0][0]))



label = "Drone" if pred > 0.9 else "Bird"
confidence = pred if pred > 0.9 else 1 - pred

print(f"Prediction: {label} | Confidence: {confidence[0][0]:.3f}")

